# LightRAG 项目架构分析

## 整体架构图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         LightRAG 智能文档检索系统                            │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────┐      ┌──────────────┐      ┌──────────────┐              │
│  │  用户接口层   │      │  后端服务层   │      │  核心引擎层   │              │
│  ├──────────────┤      ├──────────────┤      ├──────────────┤              │
│  │ • CLI (main) │      │ • RAGBackend │      │ • LightRAG   │              │
│  │ • HTTP API   │      │ • RAGService │      │ • 向量数据库  │              │
│  │ • Client SDK │      │ • Query API  │      │ • 知识图谱    │              │
│  └──────────────┘      └──────────────┘      └──────────────┘              │
│           │                      │                      │                   │
│           └──────────────────────┴──────────────────────┘                   │
│                                  │                                           │
│                                  ▼                                           │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                         文档处理流水线                               │   │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │                                                                     │   │
│  │  输入文件 ──▶ 文件识别 ──▶ 内容提取 ──▶ 文本处理 ──▶ 索引入库        │   │
│  │     │            │           │           │           │               │   │
│  │     ▼            ▼           ▼           ▼           ▼               │   │
│  │  PDF/       路由器     提取器链     清理/     批处理/                │   │
│  │  TXT/       (格式)    (多策略)     验证     去重/                   │   │
│  │  DOCX                                      断点续传                 │   │
│  │                                                                     │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                  │                                           │
│                                  ▼                                           │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                         AI 模型服务层                                │   │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │  ┌──────────────┐         ┌──────────────┐                         │   │
│  │  │ vLLM LLM     │         │ Embedding    │                         │   │
│  │  │ (Qwen2.5)    │         │ (BGE-M3)     │                         │   │
│  │  │              │         │              │                         │   │
│  │  │ • 文本理解   │         │ • 向量化     │                         │   │
│  │  │ • 实体提取   │         │ • 语义搜索   │                         │   │
│  │  │ • 关系抽取   │         │              │                         │   │
│  │  │ • 答案生成   │         │              │                         │   │
│  │  └──────────────┘         └──────────────┘                         │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

## 核心模块详解

### 1. 文档处理流水线 (`src/extractors.py`)

这是整个系统的"入口"，负责将各种格式的文件转换为可索引的文本。

#### 1.1 文件类型识别与路由

```
DocumentExtractor (统一入口)
    │
    ├─▶ FastPDFExtractor      (.pdf)
    │    ├─ 标准文本提取
    │    ├─ 备用提取模式
    │    └─ OCR 降级 (RapidOCR/PaddleOCR/Qwen2-VL)
    │
    ├─▶ FastTextExtractor     (.txt, .md, .csv, .json, .xml)
    │    ├─ chardet 自动编码检测
    │    ├─ 常见编码列表回退
    │    └─ ignore 模式最后手段
    │
    └─▶ FastDocxExtractor     (.docx)
         ├─ 段落提取
         └─ 表格提取
```

#### 1.2 提取策略（以 PDF 为例）

```python
# FastPDFExtractor 的三阶段提取策略

# 阶段 1: 标准文本提取（最快）
def _extract_standard(file_path):
    # 使用 PyMuPDF 的 get_text("text")
    # 适用于有文本层的 PDF
    # 处理速度: ~100 页/秒

# 阶段 2: 备用提取模式（兼容性更好）
def _extract_alternative_mode(file_path):
    # 尝试多种提取 flags
    # - TEXT_PRESERVE_WHITESPACE
    # - TEXT_PRESERVE_LIGATURES
    # - blocks 模式
    # - dict 模式（保留布局）
    # 选择最长的结果

# 阶段 3: OCR 降级（处理扫描件）
def _extract_with_ocr(file_path):
    # 将 PDF 页面渲染为图片 (200 DPI)
    # 调用 OCR 引擎识别
    # 支持: RapidOCR / PaddleOCR / Qwen2-VL
```

#### 1.3 错误分类系统

```python
class ExtractionErrorType(enum.Enum):
    # PDF 相关
    PDF_ENCRYPTED           # 加密 PDF
    PDF_CORRUPTED           # 损坏的 PDF
    PDF_NO_TEXT_LAYER       # 扫描件（需要 OCR）
    PDF_EMPTY               # 空白 PDF
    PDF_PARSE_ERROR         # 解析错误

    # 编码相关
    ENCODING_DETECTION_FAILED
    ENCODING_CONVERSION_ERROR

    # 文件相关
    FILE_NOT_FOUND
    FILE_TOO_LARGE
    FILE_PERMISSION_DENIED

    # 依赖相关
    DEPENDENCY_MISSING
    DEPENDENCY_VERSION
```

### 2. 并发索引管理器 (`src/index_manager.py`)

负责批量处理文件，支持断点续传和去重。

#### 2.1 核心功能

```
ConcurrentIndexer
    │
    ├─ 进度持久化 (ProgressStorage)
    │   ├─ index_progress.json   # 全局进度
    │   └─ file_records.json     # 文件记录
    │
    ├─ 文件去重 (FileHasher)
    │   └─ MD5 哈希计算
    │
    ├─ 并发处理 (Semaphore)
    │   └─ 默认 4 并发
    │
    └─ 状态管理
        ├─ 已索引
        ├─ 失败
        ├─ 跳过
        └─ 剩余
```

#### 2.2 文件处理决策树

```
文件输入
    │
    ├─ 文件存在？ ──▶ 否 ──▶ 记录错误
    │
    ├─ 已索引且未修改？ ──▶ 是 ──▶ 跳过
    │
    ├─ 计算文件哈希
    │
    ├─ 哈希已存在？ ──▶ 是 ──▶ 跳过（重复文件）
    │
    └─ 处理文件
        ├─ 提取内容
        ├─ 索引入 RAG
        └─ 更新记录
```

### 3. RAG 核心引擎 (`src/rag_engine.py`)

封装 LightRAG，提供文档索引和查询接口。

#### 3.1 LightRAG 工作原理

```
文档输入
    │
    ▼
┌─────────────────┐
│   文本分块       │  chunk_token_size=1024
│  (Chunking)     │  chunk_overlap=50
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│   实体提取       │  LLM 提取人物、组织、地点等
│ (Entity Extract)│  构建知识图谱
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│   关系抽取       │  LLM 分析实体间关系
│(Relation Extract)│  构建关系网络
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│   向量化        │  Embedding 模型
│  (Embedding)    │  生成语义向量
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│   存储到数据库   │  • 向量数据库 (Chroma)
│ (Storage)       │  • 图数据库 (NetworkX)
│                 │  • 文档存储 (KV)
└─────────────────┘
```

#### 3.2 四种查询模式

```
用户查询
    │
    ├─▶ naive    # 简单向量检索
    │   └─ 仅使用 Embedding 相似度
    │
    ├─▶ local    # 局部知识图谱
    │   └─ 查询直接相关的实体和关系
    │
    ├─▶ global   # 全局知识图谱
    │   └─ 查询跨文档的全局实体关系
    │
    └─▶ hybrid   # 混合模式（推荐）
        ├─ 结合 naive + local + global
        └─ LLM 综合多个来源生成答案
```

### 4. AI 模型服务 (`src/models.py`)

管理 LLM 和 Embedding 模型。

#### 4.1 LLM 服务

```python
LLMService
    │
    ├─ 模型: Qwen2.5-3B / 7B / 72B
    │
    ├─ 后端: vLLM (支持 8x GPU 张量并行)
    │
    ├─ 功能:
    │   ├─ acomplete()        # 异步文本补全
    │   ├─ batch_complete()   # 批量处理
    │   └─ test_connection()  # 连接测试
    │
    └─ 错误处理:
        ├─ 重试机制
        ├─ 上下文长度检测
        └─ 超时控制
```

#### 4.2 Embedding 服务

```python
EmbeddingService
    │
    ├─ 模型: BAAI/bge-m3
    │   ├─ 支持多语言（中英）
    │   ├─ 向量维度: 1024
    │   └─ 最大长度: 8192 tokens
    │
    ├─ 设备: CUDA (GPU 加速)
    │
    └─ 功能:
        ├─ encode()       # 单文本编码
        ├─ batch_encode() # 批量编码
        └─ create_embedding_function() # LightRAG 兼容接口
```

### 5. 后端服务层 (`backend/`)

提供 HTTP API 和高级查询接口。

#### 5.1 服务架构

```
RAGBackend (HTTP Server)
    │
    ├─ POST /query          # 执行查询
    ├─ GET  /status         # 服务状态
    ├─ GET  /health         # 健康检查
    └─ GET  /ready          # 就绪状态
         │
         ▼
    RAGService (业务逻辑)
         │
         ├─ query()         # 核心查询方法
         ├─ get_status()    # 状态查询
         └─ start/stop()    # 生命周期管理
              │
              ▼
         RAGEngine (核心引擎)
```

## 数据流转分析

### 索引流程 (Index Flow)

```
┌─────────────────────────────────────────────────────────────────────┐
│ 1. 用户触发索引                                                     │
│    python main.py index --input /path/to/docs                      │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 2. 扫描目录                                                         │
│    • 递归扫描子目录                                                │
│    • 过滤支持的格式 (.pdf, .txt, .docx)                            │
│    • 统计文件总数                                                  │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 3. 加载历史进度                                                     │
│    • index_progress.json  (总进度)                                  │
│    • file_records.json    (文件记录)                                │
│    • 已识别的文件哈希（去重）                                       │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 4. 过滤待处理文件                                                   │
│    • 新文件                                                        │
│    • 修改的文件                                                    │
│    • 失败重试的文件                                                │
│    • 排除重复文件（基于哈希）                                       │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 5. 并发处理 (4 workers)                                             │
│    ┌──────────────────────────────────────────────────────┐        │
│    │ Worker 1: file1.pdf ──▶ extract ──▶ index ──▶ save   │        │
│    │ Worker 2: file2.txt ──▶ extract ──▶ index ──▶ save   │        │
│    │ Worker 3: file3.pdf ──▶ extract ──▶ OCR    ──▶ save   │        │
│    │ Worker 4: file4.docx ──▶ extract ──▶ index ──▶ save   │        │
│    └──────────────────────────────────────────────────────┘        │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 6. 定期保存进度 (每 10 个文件)                                       │
│    • 更新 index_progress.json                                       │
│    • 更新 file_records.json                                         │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 7. 生成统计报告                                                     │
│    • 总文件数 / 成功 / 失败 / 跳过                                   │
│    • 按文件类型统计                                                 │
│    • 失败文件列表（按错误分组）                                     │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
                      完成
```

### 单文件处理详情 (Single File Processing)

```
file: "1.20.1 发起人协议.pdf"
    │
    ▼
┌───────────────────────────────────────────────────────────────────┐
│ 1. 文件验证                                                       │
│    ✓ 文件存在                                                     │
│    ✓ 文件可读                                                     │
│    ✓ 文件大小合理                                                 │
└────────────────────────┬──────────────────────────────────────────┘
                         │
                         ▼
┌───────────────────────────────────────────────────────────────────┐
│ 2. 格式识别 ──▶ PDF                                              │
│    路由到: FastPDFExtractor                                       │
└────────────────────────┬──────────────────────────────────────────┘
                         │
                         ▼
┌───────────────────────────────────────────────────────────────────┐
│ 3. 尝试标准文本提取                                               │
│    doc = fitz.open(file)                                         │
│    text = page.get_text("text")                                  │
│                                                                 │
│    结果: ❌ 提取内容过少 (可能是扫描件)                            │
└────────────────────────┬──────────────────────────────────────────┘
                         │
                         ▼
┌───────────────────────────────────────────────────────────────────┐
│ 4. 尝试备用提取模式                                               │
│    • TEXT_PRESERVE_WHITESPACE                                     │
│    • blocks 模式                                                  │
│    • dict 模式                                                    │
│                                                                 │
│    结果: ❌ 仍然失败                                              │
└────────────────────────┬──────────────────────────────────────────┘
                         │
                         ▼
┌───────────────────────────────────────────────────────────────────┐
│ 5. 启用 OCR 降级                                                  │
│    for page in doc:                                              │
│        pix = page.get_pixmap(matrix=mat)  # 渲染为图片            │
│        img_bytes = pix.tobytes("png")                            │
│        result = ocr_engine.recognize(img_bytes)  # RapidOCR       │
│        text += "\n".join(result.lines)                           │
│                                                                 │
│    结果: ✅ 成功提取 2,345 字符                                   │
└────────────────────────┬──────────────────────────────────────────┘
                         │
                         ▼
┌───────────────────────────────────────────────────────────────────┐
│ 6. 文本后处理                                                     │
│    • 清理多余空白                                                 │
│    • 合并换行符                                                   │
│    • 验证最小长度                                                 │
└────────────────────────┬──────────────────────────────────────────┘
                         │
                         ▼
┌───────────────────────────────────────────────────────────────────┐
│ 7. 索引入 LightRAG                                                │
│    await rag_engine.insert_documents([content])                   │
│                                                                 │
│    内部流程:                                                       │
│    • 文本分块 (chunk_size=1024)                                   │
│    • LLM 实体提取 (Qwen2.5-3B)                                    │
│    • LLM 关系抽取                                                 │
│    • Embedding 向量化 (BGE-M3)                                    │
│    • 存储到向量数据库                                             │
└────────────────────────┬──────────────────────────────────────────┘
                         │
                         ▼
┌───────────────────────────────────────────────────────────────────┐
│ 8. 更新记录                                                       │
│    file_records["1.20.1 发起人协议.pdf"] = {                      │
│        "indexed": true,                                           │
│        "index_time": "2026-01-17T07:13:15",                      │
│        "char_count": 2345,                                       │
│        "extraction_method": "ocr",                                │
│        "ocr_engine": "RapidOCR"                                   │
│    }                                                             │
└────────────────────────┬──────────────────────────────────────────┘
                         │
                         ▼
                      ✅ 完成
```

### 查询流程 (Query Flow)

```
用户查询: "文档查询流程是什么？"
    │
    ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 1. 接收查询                                                         │
│    POST /query                                                      │
│    { "query": "...", "mode": "hybrid" }                            │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 2. 向量检索 (naive)                                                │
│    query_embedding = embedding_model.encode(query)                 │
│    similar_chunks = vector_db.search(query_embedding, top_k=10)    │
│                                                                 │
│    结果: [chunk1, chunk3, chunk7, ...]                            │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 3. 局部知识图谱检索 (local)                                        │
│    entities = extract_entities(query)                             │
│    # "文档查询" ──▶ 实体: 专利, 申请                               │
│                                                                 │
│    related_entities = graph_db.find_related(entities, depth=2)    │
│    relations = graph_db.get_relations(related_entities)           │
│                                                                 │
│    结果: 实体关系子图                                              │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 4. 全局知识图谱检索 (global)                                       │
│    communities = graph_db.find_communities(entities)              │
│    # 跨文档的社区发现                                              │
│                                                                 │
│    结果: 全局实体关系                                              │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 5. 混合检索 (hybrid)                                               │
│    context = {                                                     │
│        "chunks": similar_chunks,      # 来自 naive                 │
│        "local_graph": relations,      # 来自 local                 │
│        "global_graph": communities    # 来自 global                │
│    }                                                             │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 6. LLM 生成答案                                                    │
│    prompt = f"""                                                   │
│    基于以下上下文回答问题:                                          │
│                                                                 │
│    {context}                                                       │
│                                                                 │
│    问题: {query}                                                   │
│    """                                                            │
│                                                                 │
│    answer = llm.complete(prompt)  # Qwen2.5                       │
└────────────────────────┬────────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────────┐
│ 7. 返回结果                                                         │
│    {                                                               │
│        "answer": "根据相关文档，文档查询流程包括以下步骤...",         │
│        "sources": ["doc1.pdf#p12", "doc3.pdf#p5"],                │
│        "latency_ms": 1234.5                                       │
│    }                                                              │
└─────────────────────────────────────────────────────────────────────┘
```

## 配置系统 (`config.py`)

### 配置层次结构

```python
AppConfig (主配置)
    │
    ├─ PathConfig      # 路径配置
    │   ├─ PROJECT_ROOT      # 项目根目录
    │   ├─ INPUT_DIR        # 输入文档目录
    │   ├─ WORKING_DIR      # RAG 工作目录
    │   ├─ LOG_DIR          # 日志目录
    │   └─ CONFIG_DIR       # 配置目录
    │
    ├─ LLMConfig       # LLM 模型配置
    │   ├─ MODEL_NAME        # "Qwen/Qwen2.5-3B" 或本地路径
    │   ├─ BASE_URL          # "http://localhost:PORT/v1"
    │   ├─ API_KEY           # "EMPTY"
    │   ├─ MAX_TOKENS        # 4096
    │   ├─ TEMPERATURE       # 0.7
    │   └─ TIMEOUT           # 120
    │
    ├─ EmbeddingConfig # Embedding 配置
    │   ├─ MODEL_NAME        # "BAAI/bge-m3"
    │   ├─ DEVICE            # "cuda:0"
    │   ├─ EMBEDDING_DIM     # 1024
    │   ├─ MAX_TOKEN_SIZE    # 8192
    │   └─ NORMALIZE         # True
    │
    ├─ RAGConfig       # RAG 系统配置
    │   ├─ QUERY_MODE        # "hybrid"
    │   ├─ BATCH_SIZE        # 16
    │   ├─ CHUNK_SIZE        # 1024
    │   ├─ SUPPORTED_FORMATS # (".pdf", ".txt", ".docx")
    │   ├─ ENABLE_OCR        # True  ⭐ 新增
    │   ├─ OCR_ENGINE        # "rapidocr"  ⭐ 新增
    │   └─ OCR_LANG          # "ch"  ⭐ 新增
    │
    └─ GPUConfig       # GPU 配置
        ├─ GPU_COUNT         # 8
        ├─ TENSOR_PARALLEL_SIZE  # 8
        ├─ GPU_MEMORY_UTILIZATION  # 0.80
        ├─ MAX_NUM_SEQS      # 256
        ├─ MAX_NUM_BATCHED_TOKENS  # 8192
        └─ MAX_MODEL_LEN     # 32768
```

## 错误处理策略

### 分层错误处理

```
┌────────────────────────────────────────────────────────────────┐
│ Layer 1: 文件级错误处理                                       │
│ ────────────────────────────────────────────────────────────  │
│ • 文件不存在 ──▶ 跳过，记录错误                               │
│ • 文件损坏 ──▶ 跳过，记录错误                                 │
│ • 权限拒绝 ──▶ 跳过，记录错误                                 │
│ • 编码错误 ──▶ 尝试多种编码，全部失败则跳过                    │
└────────────────────────────────────────────────────────────────┘
                          │
                          ▼
┌────────────────────────────────────────────────────────────────┐
│ Layer 2: 提取级错误处理                                       │
│ ────────────────────────────────────────────────────────────  │
│ • 标准提取失败 ──▶ 尝试备用模式                               │
│ • 备用模式失败 ──▶ 尝试 OCR (如果启用)                        │
│ • OCR 失败 ──▶ 记录详细错误，继续下一个文件                    │
└────────────────────────────────────────────────────────────────┘
                          │
                          ▼
┌────────────────────────────────────────────────────────────────┐
│ Layer 3: 索引级错误处理                                       │
│ ────────────────────────────────────────────────────────────  │
│ • LLM 超时 ──▶ 重试 3 次                                      │
│ • Embedding 失败 ──▶ 跳过该 chunk                              │
│ • 存储失败 ──▶ 记录错误，保持进度                              │
└────────────────────────────────────────────────────────────────┘
                          │
                          ▼
┌────────────────────────────────────────────────────────────────┐
│ Layer 4: 系统级错误处理                                       │
│ ────────────────────────────────────────────────────────────  │
│ • GPU OOM ──▶ 降低 batch size，重试                           │
│ • vLLM 断连 ──▶ 等待重连，恢复处理                            │
│ • 磁盘满 ──▶ 优雅停止，保存进度                               │
└────────────────────────────────────────────────────────────────┘
```

## 性能优化要点

### 1. 并发处理
- 文件级并发: 4 workers
- 批量索引: batch_size=16
- GPU 利用率: 80%+

### 2. 内存管理
- 流式处理大文件
- 及时释放 PDF 对象
- 垃圾回收优化

### 3. 缓存策略
- 文件哈希去重
- 增量索引
- 进度持久化

### 4. GPU 资源
- vLLM 张量并行 (8x GPU)
- PagedAttention 优化
- 动态批处理

## 使用建议

### 1. 首次索引
```bash
# 启用 OCR，使用默认引擎
python main.py index
```

### 2. 重试失败文件
```bash
# 只重试之前失败的文件
python main.py index --retry-failed
```

### 3. 切换 OCR 引擎
```python
# config.py
OCR_ENGINE: str = "paddleocr"  # 更高精度
```

### 4. 调优性能
```python
# config.py
CHUNK_SIZE: int = 512      # 更稳定的提取
TEMPERATURE: float = 0.1   # 更确定的输出
```
