# Qwen 模型在项目中的使用详解

## 概述

项目中使用了 **两种不同用途** 的 Qwen 模型：

| 用途 | 模型 | 版本 | 服务方式 | 配置位置 |
|------|------|------|----------|----------|
| **LLM (文本生成)** | Qwen2.5 | 3B (本地) | vLLM 服务 | [config.py:49](LightRAG_Project/config.py#L49) |
| **OCR (图像识别)** | Qwen2-VL | 7B (可选) | transformers | [extractors.py:120](LightRAG_Project/src/extractors.py#L120) |

---

## 一、Qwen2.5 作为 LLM 的使用流程

### 1.1 启动流程

```
用户执行: python main.py index
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ [main.py:62] 初始化 LLM 服务                                    │
│ ─────────────────────────────────────────────────────────────  │
│ llm = init_llm_service(                                        │
│     model_name=cfg.llm.MODEL_NAME,    # "/path/to/Qwen2.5-3B"  │
│     base_url=cfg.llm.BASE_URL,        # "http://localhost:PORT/v1" │
│     api_key=cfg.llm.API_KEY,          # "EMPTY"               │
│     max_tokens=cfg.llm.MAX_TOKENS,    # 4096                  │
│     temperature=cfg.llm.TEMPERATURE   # 0.7                   │
│ )                                                              │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [models.py:99] 创建 LLMService 实例                             │
│ ─────────────────────────────────────────────────────────────  │
│ self.client = AsyncOpenAI(                                     │
│     base_url="http://localhost:PORT/v1",  # vLLM 服务地址      │
│     api_key="EMPTY"                                           │
│ )                                                              │
│                                                                 │
│ # 测试连接                                                      │
│ self.client.chat.completions.create(                           │
│     model="Qwen2.5-3B",                                        │
│     messages=[{"role": "user", "content": "hi"}],              │
│     max_tokens=10                                             │
│ )                                                              │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [main.py:85] 创建 llm_func (适配 LightRAG 接口)                │
│ ─────────────────────────────────────────────────────────────  │
│ async def llm_func(prompt, system_prompt=None,                 │
│                    history_messages=[], **kwargs):             │
│     return await llm.acomplete(prompt, system_prompt,          │
│                               history_messages, **kwargs)      │
│                                                                 │
│ # 这个函数被传递给 LightRAG，作为 LLM 调用接口                  │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [rag_engine.py:57] 初始化 LightRAG                              │
│ ─────────────────────────────────────────────────────────────  │
│ self._rag = LightRAG(                                          │
│     working_dir=str(self.working_dir),                         │
│     llm_model_func=llm_func,      # ⬅️ Qwen 接口               │
│     embedding_func=embedding_func,                              │
│     chunk_token_size=1024,                                     │
│ )                                                              │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
                      Qwen2.5-3B 就绪
                 (等待 LightRAG 调用)
```

### 1.2 索引阶段 - Qwen 的调用时机

当文件提取完成后，内容被送入 LightRAG 索引：

```
文件提取完成: "这是一份关于文档查询的文档..."
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ [index_manager.py:331] 调用 RAG 引擎插入                        │
│ ─────────────────────────────────────────────────────────────  │
│ await self.rag_engine.insert_documents([result.content])       │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [rag_engine.py:97] LightRAG.ainsert()                          │
│ ─────────────────────────────────────────────────────────────  │
│ await self.rag.ainsert(["这是一份关于文档查询的文档..."])      │
│                                                                 │
│ # LightRAG 内部处理流程:                                        │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ Step 1: 文本分块 (Chunking)                                    │
│ ─────────────────────────────────────────────────────────────  │
│ 输入: "这是一份关于文档查询的文档..." (2000 字符)               │
│                                                                 │
│ LightRAG 按 chunk_token_size=1024 分割:                         │
│                                                                 │
│ Chunk 1: "这是一份关于文档查询的文档。文档内容是指..."              │
│ Chunk 2: "...申请流程包括以下几个步骤..."                       │
│ Chunk 3: "...需要提交的材料有..."                               │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ Step 2: 实体提取 (Entity Extraction) ⭐ Qwen 第一次调用         │
│ ─────────────────────────────────────────────────────────────  │
│ LightRAG 构造提示词:                                            │
│                                                                 │
│ prompt = """                                                    │
│ 从以下文本中提取实体和关系:                                     │
│                                                                 │
│ 文本: {Chunk 1}                                                 │
│                                                                 │
│ 请以以下格式输出:                                               │
│ Entity("实体类型", "实体名称")                                  │
│ Relationship("源实体", "关系", "目标实体")                      │
│ """                                                            │
│                                                                 │
│ 调用 llm_func(prompt)  ──▶  Qwen2.5-3B  ──▶  返回结果:          │
│                                                                 │
│ Entity("DOCUMENT", "文档查询文档")                              │
│ Entity("CONCEPT", "文档内容")                                       │
│ Entity("PROCESS", "申请流程")                                   │
│ Relationship("文档查询文档", "包含", "文档内容")                     │
│ Relationship("文档查询文档", "描述", "申请流程")                 │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ Step 3: 关系抽取 (Relation Extraction) ⭐ Qwen 第二次调用       │
│ ─────────────────────────────────────────────────────────────  │
│ 对提取的实体进一步分析关系:                                     │
│                                                                 │
│ prompt = """                                                    │
│ 基于以下实体，分析它们之间的深层关系:                           │
│                                                                 │
│ 实体: [文档查询文档, 文档内容, 申请流程, ...]                       │
│                                                                 │
│ 请发现更多关系...                                               │
│ """                                                            │
│                                                                 │
│ 调用 llm_func(prompt)  ──▶  Qwen2.5-3B  ──▶  返回关系网络       │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ Step 4: 向量化 (Embedding)                                     │
│ ─────────────────────────────────────────────────────────────  │
│ # 使用 BGE-M3 模型，不是 Qwen                                   │
│ embeddings = embedding_func([Chunk 1, Chunk 2, Chunk 3])       │
│                                                                 │
│ 输出: [[0.123, 0.456, ...],  # 1024 维向量                     │
│        [0.234, 0.567, ...],                                    │
│        [0.345, 0.678, ...]]                                    │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ Step 5: 存储到数据库                                            │
│ ─────────────────────────────────────────────────────────────  │
│ # 向量数据库 (Chroma)                                          │
│ vector_db.add(embeddings, chunks)                              │
│                                                                 │
│ # 图数据库 (NetworkX)                                          │
│ graph_db.add_entities(entities)                                │
│ graph_db.add_relations(relations)                              │
│                                                                 │
│ # 文档存储 (KV)                                                │
│ doc_store.add(chunks)                                          │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
                      索引完成
```

### 1.3 查询阶段 - Qwen 的调用时机

```
用户查询: "如何申请文档内容？"
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ [rag_engine.py:150] 调用 LightRAG.aquery()                     │
│ ─────────────────────────────────────────────────────────────  │
│ result = await self.rag.aquery(                                │
│     "如何申请文档内容？",                                           │
│     param=QueryParam(mode="hybrid")                            │
│ )                                                              │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ LightRAG hybrid 模式内部流程:                                   │
└────────────────────────┬────────────────────────────────────────┘
                         │
    ┌────────────────────┼────────────────────┐
    │                    │                    │
    ▼                    ▼                    ▼
┌─────────┐        ┌─────────┐        ┌─────────┐
│ naive   │        │ local   │        │ global  │
│ 检索     │        │ 图谱     │        │ 图谱     │
│ (向量)   │        │ (局部)   │        │ (全局)   │
└─────────┘        └─────────┘        └─────────┘
    │                    │                    │
    └────────────────────┼────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ ⭐ Qwen 第三次调用 - 生成最终答案                                │
│ ─────────────────────────────────────────────────────────────  │
│                                                                 │
│ context = {                                                     │
│     "retrieved_chunks": [                                       │
│         "文档查询流程包括...",                                   │
│         "需要提交的材料有..."                                    │
│     ],                                                         │
│     "local_graph": [                                            │
│         "文档内容 --包含--> 申请流程",                               │
│         "申请流程 --需要--> 申请材料"                            │
│     ],                                                         │
│     "global_graph": [...]                                       │
│ }                                                              │
│                                                                 │
│ prompt = f"""                                                   │
│ 基于以下上下文回答用户问题:                                     │
│                                                                 │
│ {context}                                                       │
│                                                                 │
│ 问题: 如何申请文档内容？                                             │
│                                                                 │
│ 请提供详细、准确的回答:                                         │
│ """                                                            │
│                                                                 │
│ 调用 llm_func(prompt)  ──▶  Qwen2.5-3B  ──▶  返回答案:          │
│                                                                 │
│ "根据相关文档，申请文档内容的流程如下:                              │
│  1. 准备申请材料...                                             │
│  2. 提交申请...                                                 │
│  3. 等待审查...                                                 │
│  ...                                                            │
│ 具体需要的材料包括: ..."                                       │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
                      返回给用户
```

---

## 二、Qwen2-VL 作为 OCR 的使用流程

### 2.1 何时使用 Qwen2-VL

Qwen2-VL **仅在以下情况**被使用：

1. **配置中启用 OCR**: `ENABLE_OCR = True`
2. **选择 Qwen2-VL 引擎**: `OCR_ENGINE = "qwen2_vl"`
3. **PDF 文本提取失败**: 标准模式和备用模式都失败

### 2.2 完整调用流程

```
PDF 文件: "1.20.1 发起人协议.pdf" (扫描件)
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ [extractors.py:205] FastPDFExtractor.extract()                 │
│ ─────────────────────────────────────────────────────────────  │
│ # 尝试标准文本提取                                             │
│ result = self._extract_standard(file_path)                     │
│ # ❌ 失败: PDF 提取内容过少 (可能是扫描件)                      │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [extractors.py:234] 尝试备用提取模式                            │
│ ─────────────────────────────────────────────────────────────  │
│ result = self._extract_alternative_mode(file_path)             │
│ # ❌ 失败: 备用模式提取内容过少                                 │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [extractors.py:242] 启用 OCR 降级                               │
│ ─────────────────────────────────────────────────────────────  │
│ if self.enable_ocr_fallback:                                   │
│     result = self._extract_with_ocr(file_path)                 │
│                                                                 │
│ # ✅ 进入 OCR 提取流程                                         │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [extractors.py:447] _extract_with_ocr()                        │
│ ─────────────────────────────────────────────────────────────  │
│ # 检查 OCR 引擎是否已初始化                                    │
│ if not self._ocr_engine:                                       │
│     self._ocr_engine = create_ocr_engine(                      │
│         self.ocr_engine_type,  # "qwen2_vl"                    │
│         **self.ocr_engine_kwargs                               │
│     )                                                          │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [extractors.py:195] create_ocr_engine()                        │
│ ─────────────────────────────────────────────────────────────  │
│ if engine_type == "qwen2_vl":                                  │
│     return Qwen2VLOCREngine(**kwargs)                          │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [extractors.py:120] Qwen2VLOCREngine.__init__()                │
│ ─────────────────────────────────────────────────────────────  │
│ # 加载 Qwen2-VL 模型 (第一次使用时)                            │
│ from transformers import Qwen2VLForConditionalGeneration,      │
│     AutoProcessor                                              │
│                                                                 │
│ self._model = Qwen2VLForConditionalGeneration.from_pretrained( │
│     "Qwen/Qwen2-VL-7B-Instruct",                               │
│     torch_dtype=torch.bfloat16,                                │
│     device_map="cuda:0"                                        │
│ )                                                              │
│                                                                 │
│ self._processor = AutoProcessor.from_pretrained(               │
│     "Qwen/Qwen2-VL-7B-Instruct"                                │
│ )                                                              │
│                                                                 │
│ # 模型加载完成，准备识别                                        │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [extractors.py:469] 逐页 OCR 识别                               │
│ ─────────────────────────────────────────────────────────────  │
│ for page_num, page in enumerate(doc):                          │
│     # 1. 渲染为图片                                             │
│     mat = fitz.Matrix(200 / 72, 200 / 72)                       │
│     pix = page.get_pixmap(matrix=mat)                          │
│     img_bytes = pix.tobytes("png")                             │
│                                                                 │
│     # 2. 调用 Qwen2-VL 识别 ⭐ 关键调用                        │
│     result = self._ocr_engine.recognize(img_bytes)             │
│                                                                 │
│     # 3. 提取文本                                              │
│     lines = [line[1] for line in result if line[1]]            │
│     text = "\n".join(lines)                                    │
│     content_parts.append(text)                                 │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [extractors.py:141] Qwen2VLOCREngine.recognize()               │
│ ─────────────────────────────────────────────────────────────  │
│ # 1. 转换为 PIL Image                                          │
│ image = Image.open(BytesIO(image_bytes))                       │
│                                                                 │
│ # 2. 构建提示词                                                │
│ messages = [{                                                  │
│     "role": "user",                                            │
│     "content": [                                               │
│         {"type": "image", "image": image},                      │
│         {"type": "text",                                        │
│          "text": "请识别图片中的所有文字内容，保持原有布局和格式。如果是表格，请用表格格式输出。"} │
│     ]                                                          │
│ }]                                                             │
│                                                                 │
│ # 3. 准备输入                                                 │
│ text = self._processor.apply_chat_template(                    │
│     messages, tokenize=False, add_generation_prompt=True      │
│ )                                                              │
│ inputs = self._processor(                                      │
│     text=[text], images=[image],                               │
│     padding=True, return_tensors="pt"                          │
│ ).to(self._device)                                             │
│                                                                 │
│ # 4. 生成 ⭐ Qwen2-VL 推理                                     │
│ with torch.no_grad():                                         │
│     generated_ids = self._model.generate(                      │
│         **inputs,                                              │
│         max_new_tokens=2048  # 最多生成 2048 tokens            │
│     )                                                         │
│                                                                 │
│ # 5. 解码输出                                                  │
│ output_text = self._processor.batch_decode(                    │
│     generated_ids, skip_special_tokens=True                    │
│ )[0]                                                          │
│                                                                 │
│ return [(None, output_text, 1.0)]  # 返回识别的文本           │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ 识别结果示例:                                                   │
│ ─────────────────────────────────────────────────────────────  │
│                                                                 │
│ "发起人协议                                                     │
│                                                                 │
│ 甲方: 某某科技有限公司                                           │
│ 乙方: 某某投资管理有限公司                                       │
│                                                                 │
│ 鉴于乙方拟对甲方进行投资，双方经友好协商，达成如下协议:        │
│                                                                 │
│ 第一条 投资金额                                                │
│ 乙方同意向甲方投资人民币 1000 万元...                           │
│                                                                 │
│ 第二条 投资方式                                                │
│ ..."                                                           │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│ [index_manager.py:331] 内容索引入 RAG                           │
│ ─────────────────────────────────────────────────────────────  │
│ await self.rag_engine.insert_documents([ocr_text])            │
│                                                                 │
│ # 然后回到 "一、1.2 索引阶段" 的流程                            │
│ # Qwen2.5-3B 会对 OCR 提取的文本进行实体和关系提取             │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
                      完成
```

---

## 三、Qwen 调用次数统计

### 索引阶段 (单份文档)

| 阶段 | Qwen 模型 | 调用次数 | 说明 |
|------|-----------|----------|------|
| 文件提取 | Qwen2-VL | 0-N 次 | 仅当启用 OCR 且为扫描件时 |
| 文本分块 | - | 0 | LightRAG 内部处理 |
| 实体提取 | Qwen2.5 | N 次 | N = chunk 数量 |
| 关系抽取 | Qwen2.5 | N 次 | N = chunk 数量 |
| 向量化 | - | 0 | 使用 BGE-M3 |

**示例**: 一份 10 页的 PDF 文档
- 如果是文本 PDF: 0 次 OCR + 20 次 Qwen2.5 = **20 次**
- 如果是扫描 PDF: 10 次 Qwen2-VL + 20 次 Qwen2.5 = **30 次**

### 查询阶段 (单次查询)

| 阶段 | Qwen 模型 | 调用次数 |
|------|-----------|----------|
| 向量检索 | - | 0 |
| 图谱检索 | - | 0 |
| 答案生成 | Qwen2.5 | **1 次** |

---

## 四、配置 Qwen 模型

### 4.1 配置 Qwen2.5 (LLM)

**位置**: [config.py:49](LightRAG_Project/config.py#L49)

```python
@dataclass
class LLMConfig:
    # 使用本地模型
    MODEL_NAME: str = "/path/to/Qwen2.5-3B"  # 本地模型路径

    # 或使用 HuggingFace 模型
    # MODEL_NAME: str = "Qwen/Qwen2.5-7B-Instruct"

    # vLLM 服务地址
    BASE_URL: str = "http://localhost:PORT/v1"
    API_KEY: str = "EMPTY"
    MAX_TOKENS: int = 4096
    TEMPERATURE: float = 0.7
```

### 4.2 配置 Qwen2-VL (OCR)

**位置**: [config.py:111](LightRAG_Project/config.py#L111)

```python
@dataclass
class RAGConfig:
    # 启用 OCR
    ENABLE_OCR: bool = True

    # 选择 Qwen2-VL 引擎
    OCR_ENGINE: str = "qwen2_vl"  # 或 "rapidocr", "paddleocr"

    # 识别语言
    OCR_LANG: str = "ch"  # 中文
```

**可选参数** (在代码中传递):

```python
extractor = get_extractor(
    enable_ocr=True,
    ocr_engine_type="qwen2_vl",
    ocr_engine_kwargs={
        "model_path": "Qwen/Qwen2-VL-7B-Instruct",  # 模型路径
        "device": "cuda:0"                          # GPU 设备
    }
)
```

---

## 五、性能对比

| OCR 引擎 | 速度 | 精度 | 内存占用 | 适用场景 |
|---------|------|------|----------|----------|
| **RapidOCR** | ⚡⚡⚡ 最快 | 中 | 低 (~500MB) | 大批量处理 |
| **PaddleOCR** | ⚡⚡ 中 | 高 | 中 (~2GB) | 中英文混合 |
| **Qwen2-VL** | ⚡ 慢 | 最高 | 高 (~8GB) | 复杂布局/表格 |

**建议**:
- 默认使用 RapidOCR (快速)
- 复杂文档使用 PaddleOCR (平衡)
- 特别困难的文档使用 Qwen2-VL (最高精度)

---

## 六、监控 Qwen 调用

### 查看日志

```bash
# LLM 调用日志
tail -f logs/lightrag.log | grep "llm"

# OCR 识别日志
tail -f logs/lightrag.log | grep "OCR"

# 实体提取日志
tail -f logs/lightrag.log | grep "Entity"
```

### 统计调用次数

```bash
# 索引阶段的 Qwen 调用
grep "llm" logs/lightrag.log | wc -l

# OCR 阶段的 Qwen2-VL 调用
grep "Qwen2-VL" logs/lightrag.log | wc -l
```
